{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dae7f8-5ff6-4778-be0b-8611469ad750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas \n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de222d1-9302-4a9f-a74a-ef669653ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the customer_data\n",
    "customer_data = pd.read_csv('datasets/Customer_dataset.csv',\n",
    "                            parse_dates=True,\n",
    "                            infer_datetime_format=True)\n",
    "\n",
    "# Load the app_purchases\n",
    "app_purchases = pd.read_csv('datasets/inapp_purchases_dataset.csv',\n",
    "                            parse_dates=True,\n",
    "                            infer_datetime_format=True)\n",
    "# Load the daily_revenue\n",
    "daily_revenue = pd.read_csv('datasets/Daily_revenue_dataset.csv')\n",
    "\n",
    "# Load  the user_purchases \n",
    "paywal_data = pd.read_csv('datasets/User_demographics_paywal_dataset.csv')\n",
    "\n",
    "# Print the columns of customer data\n",
    "print(customer_data.columns)\n",
    "\n",
    "# Print the columns of app_purchases\n",
    "print(app_purchases.columns)\n",
    "\n",
    "# Print the columns of customer data\n",
    "print(daily_revenue.columns)\n",
    "\n",
    "# Print the columns of app_purchases\n",
    "print(paywal.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038a4ca-c79c-40c7-8103-cb79502fab3b",
   "metadata": {},
   "source": [
    "### Experimental units: Revenue per user day\n",
    "We are going to check what happens when we add a consumable paywall to our app. A paywall is a feature of a website or other technology that requires payment from users in order to access additional content or services.\n",
    "\n",
    "Here, you'll practice calculating experimental units and baseline values related to our consumable paywall. Both measure revenue only among users who viewed a paywall. Your job is to calculate revenue per user-day, with user-day as the experimental unit.\n",
    "\n",
    "Note: paywal_data's columns are different from course dataset's columns. (I took datasets from Datacamp course. But day misload paywal_data dataset.) Beacuse of that I don't run my codes related paywal_data dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d4c3c-7891-43f5-babd-97877e19ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join our paywall wiews to the user demographics:\n",
    "purchase_data = customer_data.merge(paywal_data, how ='left', on=['uid', 'reg_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd0159c-6fb8-4e68-b673-67eb32a33e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing reg_date column type from string to datetime:\n",
    "purchase_data[\"reg_date\"] = pd.to_datetime(purchase_data.reg_date, format = '%Y-%m-%d', errors='coerce')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcda8e9-3c51-43df-a7f5-7c5a010ec400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'day'; value from the timestamp\n",
    "purchase_data.reg_date = purchase_data.reg_date.dt.floor('d')\n",
    "\n",
    "# Replace the NaN price values with 0 \n",
    "purchase_data.price = np.where(np.isnan(purchase_data.price), 0, purchase_data.price)\n",
    "\n",
    "# Aggregate the data by 'uid' & 'date'\n",
    "purchase_data_agg = purchase_data.groupby(by=['uid', 'reg_date'], as_index=False)\n",
    "revenue_user_day = purchase_data_agg.sum()\n",
    "\n",
    "# Calculate the final average\n",
    "revenue_user_day = revenue_user_day.price.mean()\n",
    "print(revenue_user_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201a2ed-db48-4cc1-aa5d-21f3e6716c2f",
   "metadata": {},
   "source": [
    "### Conversion rate sensitivities\n",
    "To mix things up, we will spend the next few exercises working with the conversion rate metric we explored in Chapter One. Specifically you will work to examine what that value becomes under different percentage lifts and look at how many more conversions per day this change would result in. First you will find the average number of paywall views and purchases that were made per day in our observed sample. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785653e-e1e2-4644-ad68-4fc607b8eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and group the datasets\n",
    "purchase_data = customer_data.merge(paywal_data,  how='inner', on=['uid'])\n",
    "purchase_data.date = purchase_data.date.dt.floor('d')\n",
    "\n",
    "# Group and aggregate our combined dataset \n",
    "daily_purchase_data = purchase_data.groupby(by=['date'], as_index=False)\n",
    "daily_purchase_data = daily_purchase_data.agg({'purchase': ['sum', 'count']})\n",
    "\n",
    "# Find the mean of each field and then multiply by 1000 to scale the result\n",
    "daily_purchases = daily_purchase_data.purchase['sum'].mean()\n",
    "daily_paywall_views = daily_purchase_data.purchase['count'].mean()\n",
    "daily_purchases = daily_purchases * 0.1\n",
    "daily_paywall_views = daily_paywall_views * 1000\n",
    "\n",
    "print(daily_purchases)\n",
    "print(daily_paywall_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51239242-7588-4776-a6cf-12b4ed3f905e",
   "metadata": {},
   "source": [
    "### Sensitivity\n",
    "Continuing with the conversion rate metric, you will now utilize the results from the previous exercise to evaluate a few potential sensitivities that we could make use of in planning our experiment. The baseline conversion_rate has been loaded for you, calculated in the same way we saw in Chapter One. Additionally the daily_paywall_views and daily_purchases values you calculated previously have been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a06ac-5aef-446f-83ba-2b0a553c5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_sensitivity = 0.1 \n",
    "\n",
    "# Find the conversion rate when increased by the percentage of the sensitivity above\n",
    "small_conversion_rate = conversion_rate * (1 + small_sensitivity) \n",
    "\n",
    "# Apply the new conversion rate to find how many more users per day that translates to\n",
    "small_purchasers = daily_paywall_views * small_conversion_rate\n",
    "\n",
    "# Subtract the initial daily_purcahsers number from this new value to see the lift\n",
    "purchaser_lift = small_purchasers - daily_purchases\n",
    "\n",
    "print(small_conversion_rate)\n",
    "print(small_purchasers)\n",
    "print(purchaser_lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30b42f-39f7-40a6-9fcc-17eac15caaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_sensitivity = 0.2\n",
    "\n",
    "# Find the conversion rate when increased by the percentage of the sensitivity above\n",
    "medium_conversion_rate = conversion_rate * (1 + medium_sensitivity) \n",
    "\n",
    "# Apply the new conversion rate to find how many more users per day that translates to\n",
    "medium_purchasers = daily_paywall_views * medium_conversion_rate\n",
    "\n",
    "# Subtract the initial daily_purcahsers number from this new value to see the lift\n",
    "purchaser_lift = medium_purchasers - daily_purchases\n",
    "\n",
    "print(medium_conversion_rate)\n",
    "print(medium_purchasers)\n",
    "print(purchaser_lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44010b5-0118-4ac7-a92b-094fa0dcf52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_sensitivity = 0.5\n",
    "\n",
    "# Find the conversion rate lift with the sensitivity above\n",
    "large_conversion_rate = conversion_rate * (1 + large_sensitivity)\n",
    "\n",
    "# Find how many more users per day that translates to\n",
    "large_purchasers = daily_paywall_views * large_conversion_rate\n",
    "purchaser_lift = large_purchasers - daily_purchases\n",
    "\n",
    "print(large_conversion_rate)\n",
    "print(large_purchasers)\n",
    "print(purchaser_lift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aaf892-7c92-49d8-8122-81bdcad1abaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Standard deviation:\n",
    "We can find the standard deviation of our data using the pandas `std()` method by passing in a vector of our statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c94909-2267-4498-b1b8-e196461ff230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of revenue per user\n",
    "revenue_variation = total_revenue.price.std()\n",
    "print(revenue_variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6267f-d2ad-4877-9396-3640fb29107f",
   "metadata": {},
   "source": [
    "### Standard error\n",
    "Previously we observed how to calculate the standard deviation using the .std() method. In this exercise, you will explore how to calculate standard deviation for a conversion rate, which requires a slightly different procedure. You will calculate this step by step in this exercise.\n",
    "\n",
    "Loaded for you is our inner merged dataset purchase_data as well as the computed conversion_rate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff3c34-57bf-4ebb-9a30-48c237e5db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the n & v quantities\n",
    "n = purchase_data.purchase.count()\n",
    "\n",
    "# Calculate the quantity \"v\"\n",
    "v = conversion_rate * (1 - conversion_rate) \n",
    "\n",
    "# Calculate the variance and standard error of the estimate\n",
    "var = v / n \n",
    "se = var**0.5\n",
    "\n",
    "print(var)\n",
    "print(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af38bb0e-cf74-4c1f-b26a-c68e36573d32",
   "metadata": {},
   "source": [
    "### Exploring the power calculation\n",
    "As discussed, power is the probability of rejecting the null hypothesis when the alternative hypothesis is true. Here you will explore some properties of the power function and see how it relates to sample size among other parameters. The get_power() function has been included and takes the following arguments in the listed order n for sample size, p1 as the baseline value, p2 as the value with lift included, and cl as the confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63080e9-d813-4b93-a9cd-0676a3641eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the test power (some details omitted)\n",
    "def get_power(n, p1, p2, cl):\n",
    "    alpha = 1 - cl\n",
    "    qu = stats.norm.ppf(1 - alpha / 2)\n",
    "    diff = abs(p2 - p1)\n",
    "    bp = (p1 + p2) / 2\n",
    "    \n",
    "    power = power_part_one + power_part_two\n",
    "    \n",
    "    return(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47389fe8-8ca7-45cf-8613-de9019d1985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the impact of sample size increase on power\n",
    "n_param_one = get_power(n=1000, p1=p1, p2=p2, cl=cl)\n",
    "n_param_two = get_power(n=2000, p1=p1, p2=p2, cl=cl)\n",
    "\n",
    "# Look at the impact of confidence level increase on power\n",
    "alpha_param_one = get_power(n=n1, p1=p1, p2=p2, cl=0.8)\n",
    "alpha_param_two = get_power(n=n1, p1=p1, p2=p2, cl=0.95)\n",
    "    \n",
    "# Compare the ratios\n",
    "print(n_param_two / n_param_one)\n",
    "print(alpha_param_one / alpha_param_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ba0ad4-f78d-4a2f-9047-3584bc819483",
   "metadata": {},
   "source": [
    "### Calculating the sample size\n",
    "You're now going to utilize the sample size function to determine how many users you need for the test and control groups under various circumstances.\n",
    "\n",
    "Included is the get_sample_size() function you viewed previously, which takes four primary arguments, power, p1, p2 and cl as described before:\n",
    "\n",
    "`def get_sample_size(power, p1, p2, cl, max_n=1000000):\n",
    "    \n",
    "    n = 1 \n",
    "    \n",
    "    while n <= max_n:\n",
    "    \n",
    "        tmp_power = get_power(n, p1, p2, cl)\n",
    "\n",
    "        if tmp_power >= power: \n",
    "       \n",
    "           return n \n",
    "        \n",
    "        else: \n",
    "        \n",
    "            n = n + 100\n",
    "\n",
    "    return \"Increase Max N Value\" `\n",
    "You will continue working with the paywall conversion rate data for this exercise, which has been pre-loaded as purchase_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c352de6-9619-4cba-bd43-d50d800837e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_size(power, p1, p2, cl, max_n=1000000):\n",
    "    n = 1 \n",
    "    while n <= max_n:\n",
    "        tmp_power = get_power(n, p1, p2, cl)\n",
    "\n",
    "        if tmp_power >= power: \n",
    "               return n \n",
    "        else: \n",
    "            n = n + 100\n",
    "\n",
    "    return \"Increase Max N Value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c039cc-ab8a-4333-b81f-c3df8229da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the demographics and purchase data to only include paywall views\n",
    "purchase_data = customer_data.merge(paywal_data, how='inner', on=['uid'])\n",
    "                            \n",
    "# Find the conversion rate\n",
    "conversion_rate = (sum(purchase_data.purchase) / purchase_data.purchase.count())\n",
    "            \n",
    "print(conversion_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91611ec-d6d4-48ce-a0bd-cd3a0f0a1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the demographics and purchase data to only include paywall views\n",
    "purchase_data = customer_data.merge(paywal_data, how='inner', on=['uid'])\n",
    "                            \n",
    "# Find the conversion rate\n",
    "conversion_rate = (sum(purchase_data.purchase) / purchase_data.purchase.count())\n",
    "\n",
    "# Desired Power: 0.8\n",
    "# CL: 0.90\n",
    "# Percent Lift: 0.1\n",
    "p2 = conversion_rate * (1 + 0.1)\n",
    "sample_size = get_sample_size(0.8, conversion_rate, p2, 0.90)\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174842ad-0e04-4e39-9ac8-882f08b8b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the conversion rate\n",
    "conversion_rate = (sum(purchase_data.purchase) / purchase_data.purchase.count())\n",
    "\n",
    "# Desired Power: 0.95\n",
    "# CL 0.90\n",
    "# Percent Lift: 0.1\n",
    "p2 = conversion_rate * (1 + 0.1)\n",
    "sample_size = get_sample_size(0.95, conversion_rate, p2, 0.90)\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef0f48-90a6-4459-b53f-547f2a5e0168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea04f42-f772-4df9-a658-58a5ba839fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
